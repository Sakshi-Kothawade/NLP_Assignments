{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OtVUiheTvo9N",
        "outputId": "965583b7-c948-4fa0-b2b6-9eacd249bfb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.3)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "resources = [\n",
        "    'punkt',\n",
        "    'punkt_tab',\n",
        "    'stopwords',\n",
        "    'averaged_perceptron_tagger',\n",
        "    'averaged_perceptron_tagger_eng',\n",
        "    'wordnet',\n",
        "    'omw-1.4',\n",
        "    'maxent_ne_chunker',\n",
        "    'maxent_ne_chunker_tab',   # üî¥ NEW REQUIRED\n",
        "    'words'\n",
        "]\n",
        "\n",
        "for resource in resources:\n",
        "    nltk.download(resource)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBtUfNJqxffh",
        "outputId": "3e8ce827-8b44-403e-d49b-129d148a565f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk import pos_tag, ne_chunk\n",
        "from collections import Counter\n",
        "import string\n",
        "\n",
        "# Sample text input\n",
        "text = input(\"Enter your text: \")\n",
        "\n",
        "print(\"\\n-----------------------------\")\n",
        "print(\"Original Text:\\n\", text)\n",
        "\n",
        "# 1Ô∏è‚É£ Sentence Tokenization\n",
        "sentences = sent_tokenize(text)\n",
        "print(\"\\nSentence Tokenization:\")\n",
        "for s in sentences:\n",
        "    print(s)\n",
        "\n",
        "# 2Ô∏è‚É£ Word Tokenization\n",
        "words = word_tokenize(text)\n",
        "print(\"\\nWord Tokenization:\")\n",
        "print(words)\n",
        "\n",
        "# 3Ô∏è‚É£ Remove Stopwords & Punctuation\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "filtered_words = [\n",
        "    word for word in words\n",
        "    if word.lower() not in stop_words and word not in string.punctuation\n",
        "]\n",
        "\n",
        "print(\"\\nAfter Stopword Removal:\")\n",
        "print(filtered_words)\n",
        "\n",
        "# 4Ô∏è‚É£ Stemming\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
        "\n",
        "print(\"\\nAfter Stemming:\")\n",
        "print(stemmed_words)\n",
        "\n",
        "# 5Ô∏è‚É£ Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "\n",
        "print(\"\\nAfter Lemmatization:\")\n",
        "print(lemmatized_words)\n",
        "\n",
        "# 6Ô∏è‚É£ POS Tagging\n",
        "pos_tags = pos_tag(filtered_words)\n",
        "print(\"\\nPOS Tagging:\")\n",
        "print(pos_tags)\n",
        "\n",
        "# 7Ô∏è‚É£ Named Entity Recognition\n",
        "print(\"\\nNamed Entity Recognition:\")\n",
        "named_entities = ne_chunk(pos_tags)\n",
        "print(named_entities)\n",
        "\n",
        "# 8Ô∏è‚É£ Word Frequency Analysis\n",
        "word_freq = Counter(filtered_words)\n",
        "print(\"\\nWord Frequency:\")\n",
        "print(word_freq)\n",
        "\n",
        "print(\"\\nMost Common Words:\")\n",
        "print(word_freq.most_common(5))\n",
        "\n",
        "print(\"\\n-----------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xdx9CiycvxiC",
        "outputId": "e3a4f9a2-6c81-43f0-bcd3-20fba7ca18b0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your text: The Ministry of Health has launched a nationwide vaccination program.\n",
            "\n",
            "-----------------------------\n",
            "Original Text:\n",
            " The Ministry of Health has launched a nationwide vaccination program.\n",
            "\n",
            "Sentence Tokenization:\n",
            "The Ministry of Health has launched a nationwide vaccination program.\n",
            "\n",
            "Word Tokenization:\n",
            "['The', 'Ministry', 'of', 'Health', 'has', 'launched', 'a', 'nationwide', 'vaccination', 'program', '.']\n",
            "\n",
            "After Stopword Removal:\n",
            "['Ministry', 'Health', 'launched', 'nationwide', 'vaccination', 'program']\n",
            "\n",
            "After Stemming:\n",
            "['ministri', 'health', 'launch', 'nationwid', 'vaccin', 'program']\n",
            "\n",
            "After Lemmatization:\n",
            "['Ministry', 'Health', 'launched', 'nationwide', 'vaccination', 'program']\n",
            "\n",
            "POS Tagging:\n",
            "[('Ministry', 'NNP'), ('Health', 'NNP'), ('launched', 'VBD'), ('nationwide', 'JJ'), ('vaccination', 'NN'), ('program', 'NN')]\n",
            "\n",
            "Named Entity Recognition:\n",
            "(S\n",
            "  (ORGANIZATION Ministry/NNP)\n",
            "  (PERSON Health/NNP)\n",
            "  launched/VBD\n",
            "  nationwide/JJ\n",
            "  vaccination/NN\n",
            "  program/NN)\n",
            "\n",
            "Word Frequency:\n",
            "Counter({'Ministry': 1, 'Health': 1, 'launched': 1, 'nationwide': 1, 'vaccination': 1, 'program': 1})\n",
            "\n",
            "Most Common Words:\n",
            "[('Ministry', 1), ('Health', 1), ('launched', 1), ('nationwide', 1), ('vaccination', 1)]\n",
            "\n",
            "-----------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bRMHVPSqweNU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}